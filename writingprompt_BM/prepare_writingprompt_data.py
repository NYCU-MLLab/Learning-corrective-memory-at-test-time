#!/usr/bin/env python3
"""
æº–å‚™ WritingPrompt å¾®èª¿æ•¸æ“š
å°‡ WritingPrompt æ•¸æ“šè½‰æ›ç‚ºé©åˆ PreCo æ¨¡å‹å¾®èª¿çš„æ ¼å¼
"""

import json
import os
import sys
from typing import List, Dict
import random

def load_writingprompt_data(file_path: str) -> List[Dict]:
    """è¼‰å…¥ WritingPrompt æ•¸æ“š"""
    data = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            data.append(json.loads(line.strip()))
    return data

def convert_to_preco_format(writingprompt_data: List[Dict]) -> List[Dict]:
    """è½‰æ›ç‚º PreCo å¾®èª¿æ ¼å¼"""
    converted_data = []
    
    for item in writingprompt_data:
        prompt = item['prompt']
        target = item['target']
        
        # å‰µå»ºè¨“ç·´æ¨£æœ¬
        # æ ¼å¼ï¼šprompt + targetï¼Œç”¨æ–¼è‡ªå›æ­¸è¨“ç·´
        full_text = f"{prompt} {target}"
        
        converted_data.append({
            'text': full_text,
            'prompt': prompt,
            'target': target
        })
    
    return converted_data

def save_converted_data(data: List[Dict], output_path: str):
    """ä¿å­˜è½‰æ›å¾Œçš„æ•¸æ“š"""
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        for item in data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')
    
    print(f"âœ… å·²ä¿å­˜ {len(data)} å€‹æ¨£æœ¬åˆ° {output_path}")

def create_train_val_split(data: List[Dict], val_ratio: float = 0.1) -> tuple:
    """å‰µå»ºè¨“ç·´/é©—è­‰åˆ†å‰²"""
    random.shuffle(data)
    
    val_size = int(len(data) * val_ratio)
    train_data = data[val_size:]
    val_data = data[:val_size]
    
    return train_data, val_data

def main():
    # è¨­å®šè·¯å¾‘
    input_file = "test_50.jsonl"  # ç•¶å‰ç›®éŒ„ä¸‹çš„æ•¸æ“šæ–‡ä»¶
    output_dir = "../../longhorn/data/writingprompt"  # ç›¸å°æ–¼ longhorn ç›®éŒ„
    
    print("ğŸ”„ æº–å‚™ WritingPrompt å¾®èª¿æ•¸æ“š")
    print("="*50)
    
    # æª¢æŸ¥è¼¸å…¥æ–‡ä»¶
    if not os.path.exists(input_file):
        print(f"âŒ æ‰¾ä¸åˆ°è¼¸å…¥æ–‡ä»¶: {input_file}")
        print("è«‹ç¢ºä¿ WritingPrompt æ•¸æ“šæ–‡ä»¶å­˜åœ¨")
        return
    
    # è¼‰å…¥åŸå§‹æ•¸æ“š
    print(f"ğŸ“– è¼‰å…¥åŸå§‹æ•¸æ“š: {input_file}")
    original_data = load_writingprompt_data(input_file)
    print(f"âœ… è¼‰å…¥äº† {len(original_data)} å€‹æ¨£æœ¬")
    
    # è½‰æ›æ ¼å¼
    print("ğŸ”„ è½‰æ›ç‚º PreCo æ ¼å¼...")
    converted_data = convert_to_preco_format(original_data)
    
    # å‰µå»ºè¨“ç·´/é©—è­‰åˆ†å‰²
    print("ğŸ”„ å‰µå»ºè¨“ç·´/é©—è­‰åˆ†å‰²...")
    train_data, val_data = create_train_val_split(converted_data, val_ratio=0.1)
    
    # ä¿å­˜æ•¸æ“š
    train_path = os.path.join(output_dir, "train.jsonl")
    val_path = os.path.join(output_dir, "val.jsonl")
    
    save_converted_data(train_data, train_path)
    save_converted_data(val_data, val_path)
    
    print(f"\nğŸ“Š æ•¸æ“šçµ±è¨ˆ:")
    print(f"  - ç¸½æ¨£æœ¬æ•¸: {len(converted_data)}")
    print(f"  - è¨“ç·´æ¨£æœ¬: {len(train_data)}")
    print(f"  - é©—è­‰æ¨£æœ¬: {len(val_data)}")
    
    # é¡¯ç¤ºæ¨£æœ¬ç¤ºä¾‹
    print(f"\nğŸ“ æ¨£æœ¬ç¤ºä¾‹:")
    for i, sample in enumerate(converted_data[:2]):
        print(f"\næ¨£æœ¬ {i+1}:")
        print(f"  Prompt: {sample['prompt'][:100]}...")
        print(f"  Target: {sample['target'][:100]}...")
        print(f"  Full text: {sample['text'][:150]}...")

if __name__ == "__main__":
    main() 